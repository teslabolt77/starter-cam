#!/usr/bin/env python3
"""
starter_capture.py â€” Sourdough starter surface detector (lid-robust)

Key fixes:
- Always defines roi_band (no NameError)
- Hard clamps search region to avoid lid/rim
- Rejects "too perfect" / low-texture candidates
- Temporal sanity check (no teleporting bread)
- Optional debug outputs (ROI + overlay)
"""

import argparse
import os
import time
from dataclasses import dataclass
from typing import Optional, Tuple

import cv2
import numpy as np


# -------------------- CONFIG DEFAULTS --------------------

# Vertical search band as fraction of image height.
# IMPORTANT: keep BOT below lid/rim zone.
DEFAULT_SEARCH_TOP_FRAC = 0.40
DEFAULT_SEARCH_BOT_FRAC = 0.78

# Candidate scoring
EDGE_BLUR_KSIZE = 5          # blur before gradients
ROW_SMOOTH_K = 21            # smooth 1D row-score curve (odd)
MIN_TEXTURE_ENERGY = 12.0    # reject too-flat rows (lid/rim often very flat)
EDGE_POWER = 1.0             # raise row score to power; >1 emphasizes peaks

# Temporal filtering
MAX_DELTA_PX = 8             # max allowed movement frame-to-frame
EMA_ALPHA = 0.35             # smoothing factor for output surface y (0..1)

# Debug
DEFAULT_DEBUG = True


# -------------------- UTIL --------------------

def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def now_stamp() -> str:
    return time.strftime("%Y%m%d_%H%M%S")


@dataclass
class DetectorState:
    prev_y: Optional[int] = None
    ema_y: Optional[float] = None


def texture_energy(gray: np.ndarray) -> float:
    """
    Simple texture measure: mean absolute Laplacian.
    Higher => more texture.
    """
    lap = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)
    return float(np.mean(np.abs(lap)))


def row_edge_score(gray: np.ndarray) -> np.ndarray:
    """
    Compute a per-row "edginess" score: sum of vertical gradients across the row.
    Strong horizontal edges produce high values.
    """
    if EDGE_BLUR_KSIZE and EDGE_BLUR_KSIZE >= 3:
        gray = cv2.GaussianBlur(gray, (EDGE_BLUR_KSIZE, EDGE_BLUR_KSIZE), 0)

    # Vertical gradient (changes in Y): highlights horizontal edges
    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
    gy = np.abs(gy)

    # Sum across columns -> one score per row
    scores = np.sum(gy, axis=1)

    # Smooth the 1D curve to reduce noise
    k = ROW_SMOOTH_K if ROW_SMOOTH_K % 2 == 1 else ROW_SMOOTH_K + 1
    if k >= 3 and scores.shape[0] >= k:
        scores = cv2.GaussianBlur(scores.reshape(-1, 1), (1, k), 0).reshape(-1)

    if EDGE_POWER != 1.0:
        scores = np.power(scores, EDGE_POWER)

    return scores


def pick_surface_row(roi_bgr: np.ndarray,
                     min_tex: float = MIN_TEXTURE_ENERGY) -> Tuple[int, float, float]:
    """
    Returns: (row_idx, best_score, tex_energy)
    row_idx is relative to roi (0..roi_h-1)
    """
    gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)

    tex = texture_energy(gray)

    scores = row_edge_score(gray)
    row = int(np.argmax(scores))
    best = float(scores[row])

    return row, best, tex


def apply_temporal_rules(raw_y: int, state: DetectorState) -> int:
    """
    Anti-teleport clamp + EMA smoothing.
    Returns stabilized y (int).
    """
    y = raw_y

    if state.prev_y is not None and abs(y - state.prev_y) > MAX_DELTA_PX:
        # Clamp big jumps
        y = state.prev_y

    # EMA smoothing
    if state.ema_y is None:
        state.ema_y = float(y)
    else:
        state.ema_y = (1.0 - EMA_ALPHA) * state.ema_y + EMA_ALPHA * float(y)

    y_out = int(round(state.ema_y))
    state.prev_y = y_out
    return y_out


# -------------------- CAPTURE --------------------

def open_camera(device: int = 0, width: int = 0, height: int = 0) -> cv2.VideoCapture:
    cap = cv2.VideoCapture(device)
    if width > 0:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
    if height > 0:
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
    return cap


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--device", type=int, default=0, help="Camera device index (default: 0)")
    ap.add_argument("--width", type=int, default=0, help="Optional capture width")
    ap.add_argument("--height", type=int, default=0, help="Optional capture height")

    ap.add_argument("--save-image", action="store_true", help="Save a captured image")
    ap.add_argument("--image-dir", default="/home/pi/starter_cam/captures", help="Output directory")
    ap.add_argument("--prefix", default="starter", help="Filename prefix")

    ap.add_argument("--search-top-frac", type=float, default=DEFAULT_SEARCH_TOP_FRAC)
    ap.add_argument("--search-bot-frac", type=float, default=DEFAULT_SEARCH_BOT_FRAC)

    ap.add_argument("--debug", action="store_true", default=DEFAULT_DEBUG, help="Write debug ROI/overlay images")
    ap.add_argument("--no-debug", action="store_true", help="Disable debug outputs")

    args = ap.parse_args()
    debug = args.debug and (not args.no_debug)

    ensure_dir(args.image_dir)

    cap = open_camera(args.device, args.width, args.height)
    if not cap.isOpened():
        print("ERROR: Could not open camera.")
        return 1

    ok, frame = cap.read()
    cap.release()

    if not ok or frame is None:
        print("ERROR: Could not read frame from camera.")
        return 2

    H, W = frame.shape[:2]

    # Hard clamp ROI band to avoid lid/rim
    y1 = int(np.clip(H * args.search_top_frac, 0, H - 2))
    y2 = int(np.clip(H * args.search_bot_frac, y1 + 1, H - 1))
    roi_band = frame[y1:y2, :].copy()  # ALWAYS defined

    # Detect surface within band
    row_rel, best_score, tex = pick_surface_row(roi_band)

    # Reject low-texture frames (common when we accidentally hit lid/rim/reflection)
    # If rejected, fallback to mid-band row to avoid nonsense.
    rejected = False
    if tex < MIN_TEXTURE_ENERGY:
        rejected = True
        row_rel = (roi_band.shape[0] // 2)

    raw_surface_y = y1 + row_rel

    # Apply temporal stabilization (single-frame run still gets a stable output)
    state = DetectorState(prev_y=raw_surface_y, ema_y=float(raw_surface_y))
    surface_y = apply_temporal_rules(raw_surface_y, state)

    # Save main capture if requested
    if args.save_image:
        out_path = os.path.join(args.image_dir, f"{args.prefix}_{now_stamp()}.jpg")
        cv2.imwrite(out_path, frame)
        print(out_path)

    # Debug outputs
    if debug:
        roi_path = os.path.join(args.image_dir, f"{args.prefix}_roi_{now_stamp()}.jpg")
        cv2.imwrite(roi_path, roi_band)

        overlay = frame.copy()
        # ROI bounds (yellow)
        cv2.line(overlay, (0, y1), (W - 1, y1), (0, 255, 255), 1)
        cv2.line(overlay, (0, y2), (W - 1, y2), (0, 255, 255), 1)
        # Surface line (green)
        cv2.line(overlay, (0, surface_y), (W - 1, surface_y), (0, 255, 0), 2)

        label = f"surface_y={surface_y} raw={raw_surface_y} tex={tex:.1f} score={best_score:.1f}"
        if rejected:
            label += " REJECTED(low_texture)"
        cv2.putText(overlay, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        ov_path = os.path.join(args.image_dir, f"{args.prefix}_overlay_{now_stamp()}.jpg")
        cv2.imwrite(ov_path, overlay)

    # Print the detected surface y (useful if you parse output)
    print(f"SURFACE_Y {surface_y} (raw {raw_surface_y}) ROI[{y1}:{y2}] tex={tex:.1f} score={best_score:.1f}{' REJECTED' if rejected else ''}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
