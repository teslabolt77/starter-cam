#!/usr/bin/env python3
"""
starter_capture.py â€” Sourdough starter surface detector (lid-robust + brightness-stable)

What this version does:
- Hard clamps search region to avoid lid/rim
- Detects surface via vertical intensity transition (better for low-contrast dough)
- Confidence + temporal sanity (no teleporting bread)
- Optional v4l2-ctl camera control locking (fixes sudden dark frames)
- Writes debug ROI + overlay images
"""

import argparse
import os
import time
import shutil
import subprocess
from dataclasses import dataclass
from typing import Optional, Tuple

import cv2
import numpy as np


# -------------------- DEFAULTS --------------------
DEFAULT_SEARCH_TOP_FRAC = 0.40
DEFAULT_SEARCH_BOT_FRAC = 0.80  # keep below lid/rim

# Detection smoothing
ROW_SMOOTH_K = 21  # odd
GRAY_BLUR = 9      # odd

# Confidence threshold for intensity transition peak
DEFAULT_MIN_CONF = 1.2

# Temporal smoothing
MAX_DELTA_PX = 10
EMA_ALPHA = 0.35

# Debug default
DEFAULT_DEBUG = True


# -------------------- UTIL --------------------
def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)

def now_stamp() -> str:
    return time.strftime("%Y%m%d_%H%M%S")

@dataclass
class DetectorState:
    prev_y: Optional[int] = None
    ema_y: Optional[float] = None


# -------------------- CAMERA CONTROL (v4l2-ctl) --------------------
def have_v4l2ctl() -> bool:
    return shutil.which("v4l2-ctl") is not None

def run_v4l2ctl(args_list) -> None:
    # silent failure is OK; we don't want the whole run to die because a control isn't supported
    try:
        subprocess.run(["v4l2-ctl", *args_list], check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except Exception:
        pass

def apply_camera_controls(device_index: int,
                          auto: Optional[str],
                          exposure: Optional[int],
                          gain: Optional[int],
                          brightness: Optional[int],
                          contrast: Optional[int],
                          gamma: Optional[int],
                          sharpness: Optional[int],
                          wb_auto: Optional[str],
                          wb_temp: Optional[int]) -> None:
    """
    Best-effort lock down camera settings to stop sudden darkness.
    Uses /dev/video{device_index}.
    """
    if not have_v4l2ctl():
        return

    dev = f"/dev/video{device_index}"

    # Auto exposure mode naming varies by camera driver.
    # Common controls:
    #   exposure_auto: 0=auto, 1=manual (sometimes 3=aperture priority)
    # We'll try sensible values without crashing if unsupported.
    if auto is not None:
        if auto.lower() == "off":
            run_v4l2ctl(["-d", dev, "-c", "exposure_auto=1"])
        elif auto.lower() == "on":
            run_v4l2ctl(["-d", dev, "-c", "exposure_auto=0"])

    if exposure is not None:
        # Often "exposure_absolute"
        run_v4l2ctl(["-d", dev, "-c", f"exposure_absolute={exposure}"])

    if gain is not None:
        run_v4l2ctl(["-d", dev, "-c", f"gain={gain}"])

    if brightness is not None:
        run_v4l2ctl(["-d", dev, "-c", f"brightness={brightness}"])

    if contrast is not None:
        run_v4l2ctl(["-d", dev, "-c", f"contrast={contrast}"])

    if gamma is not None:
        run_v4l2ctl(["-d", dev, "-c", f"gamma={gamma}"])

    if sharpness is not None:
        run_v4l2ctl(["-d", dev, "-c", f"sharpness={sharpness}"])

    if wb_auto is not None:
        if wb_auto.lower() == "off":
            run_v4l2ctl(["-d", dev, "-c", "white_balance_temperature_auto=0"])
        elif wb_auto.lower() == "on":
            run_v4l2ctl(["-d", dev, "-c", "white_balance_temperature_auto=1"])

    if wb_temp is not None:
        run_v4l2ctl(["-d", dev, "-c", f"white_balance_temperature={wb_temp}"])


# -------------------- DETECTION --------------------
def pick_surface_row_intensity(roi_bgr: np.ndarray) -> Tuple[int, float]:
    """
    Find surface by largest consistent vertical intensity drop (row-wise projection).
    Returns (row_idx_rel_to_roi, confidence).
    """
    gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)

    # Stabilize noise
    k = GRAY_BLUR if GRAY_BLUR % 2 == 1 else GRAY_BLUR + 1
    if k >= 3:
        gray = cv2.GaussianBlur(gray, (k, k), 0)

    # Mean intensity per row
    row_means = np.mean(gray, axis=1)  # shape (H,)

    # Downward change (positive means it got darker going down)
    diff = row_means[:-1] - row_means[1:]  # shape (H-1,)

    # Smooth 1D curve
    sk = ROW_SMOOTH_K if ROW_SMOOTH_K % 2 == 1 else ROW_SMOOTH_K + 1
    if sk >= 3 and diff.shape[0] >= sk:
        diff = cv2.GaussianBlur(diff.reshape(-1, 1), (1, sk), 0).ravel()

    row = int(np.argmax(diff))
    conf = float(diff[row])
    return row, conf


def apply_temporal(raw_y: int, state: DetectorState) -> int:
    y = raw_y
    if state.prev_y is not None and abs(y - state.prev_y) > MAX_DELTA_PX:
        y = state.prev_y

    if state.ema_y is None:
        state.ema_y = float(y)
    else:
        state.ema_y = (1.0 - EMA_ALPHA) * state.ema_y + EMA_ALPHA * float(y)

    y_out = int(round(state.ema_y))
    state.prev_y = y_out
    return y_out


# -------------------- CAPTURE --------------------
def open_camera(device: int, width: int, height: int) -> cv2.VideoCapture:
    cap = cv2.VideoCapture(device)
    if width > 0:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
    if height > 0:
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
    return cap


def main() -> int:
    ap = argparse.ArgumentParser()

    # Camera basics
    ap.add_argument("--device", type=int, default=0)
    ap.add_argument("--width", type=int, default=0)
    ap.add_argument("--height", type=int, default=0)

    # Output
    ap.add_argument("--save-image", action="store_true")
    ap.add_argument("--image-dir", default="/home/pi/starter_cam/captures")
    ap.add_argument("--prefix", default="starter")

    # ROI clamp
    ap.add_argument("--search-top-frac", type=float, default=DEFAULT_SEARCH_TOP_FRAC)
    ap.add_argument("--search-bot-frac", type=float, default=DEFAULT_SEARCH_BOT_FRAC)

    # Detection confidence
    ap.add_argument("--min-conf", type=float, default=DEFAULT_MIN_CONF)

    # Debug
    ap.add_argument("--debug", action="store_true", default=DEFAULT_DEBUG)
    ap.add_argument("--no-debug", action="store_true")

    # v4l2 camera control locking (optional but recommended)
    ap.add_argument("--auto", choices=["on", "off"], default=None, help="exposure auto on/off (v4l2-ctl)")
    ap.add_argument("--exposure", type=int, default=None, help="exposure_absolute (v4l2-ctl)")
    ap.add_argument("--gain", type=int, default=None, help="gain (v4l2-ctl)")
    ap.add_argument("--brightness", type=int, default=None, help="brightness (v4l2-ctl)")
    ap.add_argument("--contrast", type=int, default=None, help="contrast (v4l2-ctl)")
    ap.add_argument("--gamma", type=int, default=None, help="gamma (v4l2-ctl)")
    ap.add_argument("--sharpness", type=int, default=None, help="sharpness (v4l2-ctl)")
    ap.add_argument("--wb-auto", choices=["on", "off"], default=None, help="white_balance_temperature_auto (v4l2-ctl)")
    ap.add_argument("--wb-temp", type=int, default=None, help="white_balance_temperature (v4l2-ctl)")

    args = ap.parse_args()
    debug = args.debug and (not args.no_debug)

    ensure_dir(args.image_dir)

    # Apply camera controls BEFORE capture (best-effort)
    apply_camera_controls(
        device_index=args.device,
        auto=args.auto,
        exposure=args.exposure,
        gain=args.gain,
        brightness=args.brightness,
        contrast=args.contrast,
        gamma=args.gamma,
        sharpness=args.sharpness,
        wb_auto=args.wb_auto,
        wb_temp=args.wb_temp,
    )

    cap = open_camera(args.device, args.width, args.height)
    if not cap.isOpened():
        print("ERROR: Could not open camera.")
        return 1

    ok, frame = cap.read()
    cap.release()
    if not ok or frame is None:
        print("ERROR: Could not read frame.")
        return 2

    H, W = frame.shape[:2]

    # Hard clamp ROI band (lid avoidance)
    y1 = int(np.clip(H * args.search_top_frac, 0, H - 2))
    y2 = int(np.clip(H * args.search_bot_frac, y1 + 1, H - 1))
    roi = frame[y1:y2, :].copy()

    # Detect
    row_rel, conf = pick_surface_row_intensity(roi)
    rejected = conf < args.min_conf
    if rejected:
        row_rel = roi.shape[0] // 2

    raw_y = y1 + row_rel

    # Single-frame run: init state from this reading (still gives consistent number)
    state = DetectorState(prev_y=raw_y, ema_y=float(raw_y))
    y = apply_temporal(raw_y, state)

    # Save main capture
    if args.save_image:
        img_path = os.path.join(args.image_dir, f"{args.prefix}_{now_stamp()}.jpg")
        cv2.imwrite(img_path, frame)
        print(img_path)

    # Debug outputs
    if debug:
        roi_path = os.path.join(args.image_dir, f"{args.prefix}_roi_{now_stamp()}.jpg")
        cv2.imwrite(roi_path, roi)

        overlay = frame.copy()
        cv2.line(overlay, (0, y1), (W - 1, y1), (0, 255, 255), 1)
        cv2.line(overlay, (0, y2), (W - 1, y2), (0, 255, 255), 1)
        cv2.line(overlay, (0, y), (W - 1, y), (0, 255, 0), 2)

        label = f"surface_y={y} row={row_rel} conf={conf:.2f} ROI[{y1}:{y2}]"
        if rejected:
            label += " REJECTED(low_conf)"
        cv2.putText(overlay, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        ov_path = os.path.join(args.image_dir, f"{args.prefix}_overlay_{now_stamp()}.jpg")
        cv2.imwrite(ov_path, overlay)

    print(f"SURFACE_Y {y} raw={raw_y} conf={conf:.2f} ROI[{y1}:{y2}]{' REJECTED' if rejected else ''}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
